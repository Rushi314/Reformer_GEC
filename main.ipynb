{"cells":[{"cell_type":"markdown","metadata":{"id":"oEM9T7R889hU"},"source":["# Fetch Files from GitHub\n","Running this more than once won't break anything!"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19062,"status":"ok","timestamp":1634753531829,"user":{"displayName":"Shubham Shetty","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gift8m3G6SXjNLimI9-jKJTPDMNVC-Cto60CKMc=s64","userId":"02610804697838200174"},"user_tz":240},"id":"wAmMJbKH5jy2","outputId":"5c214767-0263-4e41-a09b-682cbf4c0c04"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: sample_data: No such file or directory\n","rm: .config: No such file or directory\n","fatal: destination path '.' already exists and is not an empty directory.\n"]}],"source":["!rm -r sample_data .config\n","!git clone https://github.com/shubham-shetty/Reformer_GEC.git ."]},{"cell_type":"markdown","metadata":{},"source":["# Random Code\n","Feel free to mess with this"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: 100%|██████████| 569M/569M [01:59<00:00, 4.99MB/s]\n","Some weights of the model checkpoint at google/reformer-enwik8 were not used when initializing ReformerModel: ['reformer.embeddings.position_embeddings.weights.1', 'lm_head.decoder.weight', 'lm_head.bias', 'reformer.embeddings.position_embeddings.weights.0', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing ReformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ReformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ReformerModel were not initialized from the model checkpoint at google/reformer-enwik8 and are newly initialized: ['reformer.embeddings.position_embeddings.embedding.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["DeletionReformer(\n","  (reformer): ReformerModel(\n","    (embeddings): ReformerEmbeddings(\n","      (word_embeddings): Embedding(258, 1024)\n","      (position_embeddings): PositionEmbeddings(\n","        (embedding): Embedding(65536, 1024)\n","      )\n","    )\n","    (encoder): ReformerEncoder(\n","      (layers): ModuleList(\n","        (0): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (1): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (2): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LSHSelfAttention(\n","              (query_key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (3): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (4): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (5): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (6): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LSHSelfAttention(\n","              (query_key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (7): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (8): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (9): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (10): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LSHSelfAttention(\n","              (query_key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","        (11): ReformerLayer(\n","          (attention): ReformerAttention(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (self_attention): LocalSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=False)\n","              (key): Linear(in_features=1024, out_features=1024, bias=False)\n","              (value): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","            (output): ReformerSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=False)\n","            )\n","          )\n","          (feed_forward): ChunkReformerFeedForward(\n","            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dense): ReformerFeedForwardDense(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            )\n","            (output): ReformerFeedForwardOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            )\n","          )\n","        )\n","      )\n","      (layer_norm): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n","    )\n","  )\n","  (linear): Linear(in_features=2048, out_features=1, bias=True)\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from code.models.deletion_reformer import DeletionReformer\n","\n","deleter = DeletionReformer()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNyjbU13gvI0YtgmVk+yBH1","collapsed_sections":[],"name":"test.ipynb","provenance":[]},"interpreter":{"hash":"e543b8c8d8c06e0cea0a1fa2606d0c5202e501054a9c79f4401a14388e75d1a9"},"kernelspec":{"display_name":"Python 3.9.5 64-bit ('neural': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"}},"nbformat":4,"nbformat_minor":0}
